{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2_Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run these Regardless"
      ],
      "metadata": {
        "id": "fdCMeWfA0Vgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple"
      ],
      "metadata": {
        "id": "8CapKsvllsuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "#from nltk.translate import bleu\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "#from rouge_score import rouge_scorer\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "metadata": {
        "id": "GdGnvcRwXDLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155386f3-ed83-4244-89f2-b9782dab7414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQ9wn5dfiBz"
      },
      "source": [
        "# Fine-tuning GPT-2 on a Custom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL4ht6hRHj1W"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLvhw96EXK5"
      },
      "source": [
        "Make sure you enable a GPU or TPU in the runtime  \n",
        "Runtime -> Change Runtime -> Hardware Accelerator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvlc3CXwhDal"
      },
      "source": [
        "Download GPT-2 models.  \n",
        "When fine-tuning on a single GPU, only the 124M and 335M size models can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd9a813-ed51-4959-9762-26a87878ba70"
      },
      "source": [
        "model_size = '124M'\n",
        "gpt2.download_gpt2(model_name=model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 303Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 3.10Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 422Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:17, 28.0Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 490Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.99Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 3.94Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mLQqkm5G-A1"
      },
      "source": [
        "Set variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "# custom_dataset.txt should be in the drive without being inside any folder\n",
        "file_name = \"custom_dataset.txt\"\n",
        "run_name = 'fine_tuning_run_1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5nqoJ_IhcAj"
      },
      "source": [
        "If your custom data is stored in your G-Drive, mount your drive and you can copy the data to Colab with the code below.  \n",
        "Alternatively, you can upload your dataset directly to Colab using the Colab \"Files\" menu on the left (not the \"File\" menu above).  \n",
        "Training examples in the dataset file should be separated with a blank line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa7de2d-a228-4d48-ccec-24e151b8f29a"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform fine-tuning"
      ],
      "metadata": {
        "id": "8QF0ns9h6Gvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this when you want to save the model to google drive\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name)"
      ],
      "metadata": {
        "id": "8XTYdKUMmUPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If we want to train for first time\n",
        "batch_text = open(\"batch_text.txt\", 'w')\n",
        "counter = 1\n",
        "with open(\"custom_dataset.txt\", 'r') as f:\n",
        "  for line in f:\n",
        "    if batch_text.closed:\n",
        "      batch_text = open(\"batch_text.txt\", 'w')\n",
        "    batch_text.write(line)\n",
        "    if counter == 200: \n",
        "      ops.reset_default_graph()\n",
        "      sess = gpt2.start_tf_sess()\n",
        "      gpt2.finetune(sess,\n",
        "                    dataset=\"batch_text.txt\",\n",
        "                    model_name=model_size,\n",
        "                    steps=100,\n",
        "                    restore_from=\"fresh\",\n",
        "                    run_name = run_name,\n",
        "                    print_every=1,\n",
        "                    sample_every=20,\n",
        "                    save_every=50,\n",
        "                    reuse=False)\n",
        "      batch_text.close()\n",
        "    counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr2khphLj2p8",
        "outputId": "8f294295-64e7-480d-a63f-74db02bedd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [02:51<00:00, 171.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 26319678 tokens\n",
            "Training...\n",
            "[1 | 124.30] loss=3.48 avg=3.48\n",
            "[2 | 240.94] loss=3.38 avg=3.43\n",
            "[3 | 357.79] loss=3.40 avg=3.42\n",
            "[4 | 472.93] loss=3.47 avg=3.43\n",
            "[5 | 595.65] loss=3.45 avg=3.44\n",
            "[6 | 711.97] loss=3.35 avg=3.42\n",
            "[7 | 827.95] loss=3.27 avg=3.40\n",
            "[8 | 942.84] loss=3.24 avg=3.38\n",
            "[9 | 1057.87] loss=3.24 avg=3.36\n",
            "[10 | 1176.94] loss=3.42 avg=3.37\n",
            "[11 | 1292.97] loss=3.13 avg=3.35\n",
            "[12 | 1408.72] loss=2.84 avg=3.30\n",
            "[13 | 1524.81] loss=3.08 avg=3.28\n",
            "[14 | 1640.81] loss=3.25 avg=3.28\n",
            "[15 | 1758.71] loss=2.97 avg=3.26\n",
            "[16 | 1879.18] loss=3.00 avg=3.24\n",
            "[17 | 1996.34] loss=2.85 avg=3.22\n",
            "[18 | 2112.95] loss=3.50 avg=3.23\n",
            "[19 | 2229.54] loss=3.34 avg=3.24\n",
            "[20 | 2346.56] loss=2.78 avg=3.21\n",
            "======== SAMPLE 1 ========\n",
            "�-BOT. The following is a picture of it in the French style or an illustration. From the English, an expression may be read--\"The present is the present, there will not be another; nothing will be the present: the present is the present, there will be another; a world of future things will exist. The present is the present, there will be another.\" This expression is taken from the expression of the spirit, for which it is to be taken, with the sense of the word present. Now an expression may be taken only in the sense which is present; but only in the sense, of what is present, and not only in those circumstances which cannot be known by a look-see. For an expression, and an object, is an object, since in that case a feeling or feeling is already present; hence it is a feeling; but it is no feeling at all; in fact, the object is an object, as if it were a feeling. For an expression is not an object, but no feeling is here seen or imagined by a look-see. On the other hand, an object is not, but is not an object; and if it were, its feeling would become an object, or at least a sense of itself. Now that these can be distinct expressions with a feeling of one kind or of another, but not within a sense to be distinguished, we shall consider in turn the subject, as it seems to us. An object is an object for no other reason than this; since an object is a feeling for its being present, and the feeling to be, while this object is an object, would have been in a sense to be more than the feeling; but in a sense to be present, and to be understood, and to be thought; which means that a feeling or feeling, even a feeling for the object, is a distinct expression, because it is one with the object, and for no other reason than this. For this reason, and of course for this, we can never see what it can possibly be, and how it can be understood, but the object in the sense of any moment, which is not there of present to the world. And this is what makes a sense of an object, as I have said. It is not any feeling of that kind which an object may produce in its mind (a sense, not just a feeling). It is, instead, no feeling which may be of a sort only to a feeling. It is not that a sense may seem like to another at the same time, in the moment and in another, but a feeling, a feeling for one moment and for another. This is what gives sensation to the thing; but the feeling can be conceived but with these three words: 'the present is the present.' In the same sense, which is the feeling of the present, a feeling is the feeling for the future, and for future, and for future; but as a thing is the thing not only to the present and its future, but even to past and future, both of them. This is not a subject to the subject here cited, but to the object here cited. Now the present is the present, not only to the world, but to every moment, if it have a time, and every moment after, for the present to be the present, as the present to a moment. Now this will be remembered, because it is not for some object that a sense is made, since the world is a thing to some time after, of some time after, but not to the present, nor to the present to all eternity, so in some sense it is made at each instant, but not, though no longer. Besides, a sense is a thing, but this is a feeling. But, since it is not an object, then its idea is its act, since each thing has its object, and it can think, but if the idea is present, it cannot thought. Now, since an idea is the object, because it exists, all the other parts which is an object, which is a feeling, be made possible. It can think, but is a feeling which exists, and its act is not only an act, but an thing. If a feeling is a thing, it is a feeling, because it is, and it can think; and the idea may be a feeling by reason, but it is not an idea, because a sense is a thing, and is no idea; and a thought or feeling is a feeling, since the thoughts and feelings which are different are different; but every impression and perception are not the same thing. Now, just as the thought is an idea, so the impression and perception is different; but when the impression is, it cannot think; so the perception is a perception, but an impression and an impression; and an impression or impression is an idea, if only it was the idea that made it, for then no idea is a perception. Now, the idea may be thought.\n",
            "\n",
            "[21 | 2572.02] loss=3.43 avg=3.23\n",
            "[22 | 2688.34] loss=2.93 avg=3.21\n",
            "[23 | 2804.51] loss=3.35 avg=3.22\n",
            "[24 | 2920.86] loss=3.34 avg=3.22\n",
            "[25 | 3038.05] loss=3.64 avg=3.24\n",
            "[26 | 3154.98] loss=3.39 avg=3.25\n",
            "[27 | 3271.64] loss=3.05 avg=3.24\n",
            "[28 | 3388.19] loss=3.15 avg=3.24\n",
            "[29 | 3504.53] loss=3.21 avg=3.23\n",
            "[30 | 3620.99] loss=3.27 avg=3.24\n",
            "[31 | 3736.92] loss=3.17 avg=3.23\n",
            "[32 | 3858.53] loss=3.20 avg=3.23\n",
            "[33 | 3975.91] loss=3.17 avg=3.23\n",
            "[34 | 4092.79] loss=3.25 avg=3.23\n",
            "[35 | 4209.60] loss=3.26 avg=3.23\n",
            "[36 | 4326.07] loss=3.54 avg=3.24\n",
            "[37 | 4442.62] loss=3.09 avg=3.24\n",
            "[38 | 4559.34] loss=3.45 avg=3.24\n",
            "[39 | 4676.12] loss=3.24 avg=3.24\n",
            "[40 | 4792.56] loss=3.66 avg=3.26\n",
            "======== SAMPLE 1 ========\n",
            " the one with the two hands of the Lord; and the latter made an abode under the Lord upon his own lands, while he gave thanks for the service of his God; that is, his Lord's servant should obey him; and while he was in the habitations of the Apostles, he took up the mantle from the right hand of the Lord: therefore the Lord is called God. It is no wonder that, seeing that His servant had fallen upon the cross, His servant was called God and His Lord was called Him to be the only. And how could we be of that idea as I have mentioned before how God did such a thing. To that same reason of being as a man and a man to God is not only the best, but the most perfect answer. For, seeing both of the different parts of mankind, we ought to be, at least, both wise and prudent; and for the wise and prudent we ought to be as much as possible. But not only are you and the Lord your forefathers, but one for the other; for the wise and prudent ye belong only to the one, whereas for the wise the wise belongs to the other; and also the wise has an obligation to the other, for they are both to one person, and therefore both wise and prudent to the Lord; therefore the wise hath an obligation to the wise, and the wise hath an obligation only to the Lord. If, however, you want that which God hath done, ye must do it now and then at some particular time. Therefore ye must do it only in the first instance, the first which God hath done. Therefore is it not the wise, but the wise that is the wise in regard of the other, the wise in regard of the wise. Thus also hath God done it to the wise, to the wise, to the wise, to the wise; and hath done it to a few to all the people of God. So the Lord will judge the people of the world when we judge the people of God. To this purpose also He made the right hand of the Lord into the shape of the right hand, and the left hand of the Lord into the shape of the left hand: therefore they all know the right hand, and the right hand understand the left. They all also understand the right, and the left understand the left. And since they have comprehended the right hand, and the left understands, so the Lord will judge the people of the world in the same manner. Hence also He is made known all things in the world before the people of God. That is, they shall be judged before the people of God. And the Lord will judge the people of the world and the Lord shall judge the people of God. God therefore has a judge and judge is the judge; and is the judge God himself. What do you mean, judge your own things, and judge others' things? Then judge those things. How can you not judge yours? But what do you not judge that is yours? judge only who was made in the image of God. What do you not judge that is his? judge the man you do not judge? for you do what it says, judge only you, judge yourself, judge yourself, judge yourself, judge others. Judge only and be your judge; but you who judge your own things, the first you judge; the second judge you judge. Thus also the Lord has a judge. The judge is called the judge. The judge is called the judge. The judge is called the judge. The judge is called 'the judge.' The judge is called 'the judge.' The judge is called 'the judge.' The judge is 'the judge.' The judge is the judge. The judge is the judge, and the judge is the judge. The judge is called 'the judge.' Judge is the judge. Judge is the judge. The judge is called 'The judge.' The judges are judges. Judges are the judges. But the judge is the 'judge.' The judge is the judge. Judges are the judges. But the judge is the 'judges.' The judge is the 'judges.' Judges are the judges. But the judge is the first judge. The judges are the first judges. Judges are the first judge's. But the judge is the third judge. The judges are the third judges to be judged. But the judge is the third judge to be judged. The judge is the third to be judged. Judges are the third judge to be judged. God therefore will judge His own life by a trial to find out whether the judge is the first Judge. Therefore judge with justice, and be your judge. He who can judge is the judge and judge also. Therefore judge and be your judge. God is God, and he is the judge. If God does not judge, judge. But if God judge, and God should judge all, Judge is his fellow, the Judge is the judge. If God is not the judge, judge but God: and if He judges not, then you\n",
            "\n",
            "[41 | 5009.36] loss=3.30 avg=3.26\n",
            "[42 | 5126.32] loss=3.61 avg=3.27\n",
            "[43 | 5243.09] loss=3.00 avg=3.26\n",
            "[44 | 5359.76] loss=3.29 avg=3.26\n",
            "[45 | 5475.76] loss=3.21 avg=3.26\n",
            "[46 | 5592.44] loss=3.12 avg=3.26\n",
            "[47 | 5709.59] loss=3.44 avg=3.26\n",
            "[48 | 5826.48] loss=3.18 avg=3.26\n",
            "[49 | 5949.10] loss=3.08 avg=3.25\n",
            "[50 | 6065.32] loss=3.28 avg=3.25\n",
            "Saving checkpoint/fine_tuning_run_1/model-50\n",
            "[51 | 6191.27] loss=3.26 avg=3.25\n",
            "[52 | 6308.82] loss=3.43 avg=3.26\n",
            "[53 | 6425.03] loss=2.82 avg=3.25\n",
            "[54 | 6541.27] loss=3.09 avg=3.24\n",
            "[55 | 6658.64] loss=3.14 avg=3.24\n",
            "[56 | 6774.59] loss=2.83 avg=3.23\n",
            "[57 | 6892.66] loss=3.05 avg=3.23\n",
            "[58 | 7008.96] loss=3.06 avg=3.22\n",
            "[59 | 7125.57] loss=2.99 avg=3.22\n",
            "[60 | 7242.19] loss=2.83 avg=3.21\n",
            "======== SAMPLE 1 ========\n",
            " Lady? Yes indeed it was, when you come home to see me now with your own eyes. Yes, it is a pity—I would like to know that my love-struck mother is here, and her husband. I will not get all the answers to this; but I must confess, though I have a little trouble in mind, that I do not think anything of it. My dear wife, my dear wife!\" (This is a very strange thing; we read of it more than once in the book.) \"I can hardly believe you, Monsieur—I, perhaps, do not like what I see,\" continued the boy, looking from one side to the other. \"But I know you love me when you can!\" \"Not one!\" replied the young man; and he began at last to cry; in truth, and the last cry that came from him was, \"Darling, dear, my dear. Are you a little boy? Darryl! Who can be better. Oh, Monsieur Vauch!\" \"Darryl!\" \"Darryl!\" \"Darryl!\" And the sound turned on him. Monsieur Vauch cried, and at last he got up, but he soon became unquenchable. \"I have a question?\" he exclaimed, and went into a very long pause of explanation. \"Your question—your question?\" The boy did not answer him, and suddenly looked in the direction where the question came from. \"Yes,\" observed the young man; \"but in all cases there seems to be no reason to suspect it. If he were alone in the village, it might be possible, but not always possible, of him being present, or perhaps even in the company of others. If he were himself present, then, Monsieur Vauch's whole soul might be shaken and his thoughts might be filled with a terrible emotion, so that his soul might fall into despair, though he never looked back. He was still asleep before his mother, and he now trembled in her hands as soon as he saw her. In order to make her aware of the whole matter, he took her hand and said to her, \"Don't you know, Monsieur Vauch? Yes, I think so, myself; but I don't think it possible for the moment. You must see, Monsieur Vauch, what I say. You must see it yourself.\" \"I, Monsieur Vauch, I suppose it is, that I am not mistaken in it,\" said his mother; \"but I must confess it that Monsieur Vauch has not always been a little too well treated of in his family.\" \"Oh, Monsieur Vauch—why don't you tell me all?\" asked the boy; and he began to answer with a very different question. \"How can I possibly be the cause of my mother going to France? If my mother is on a mission to France, it will be impossible for me to get out of here without her having her hair cut. I may marry your daughter—don't even think about marrying her, Monsieur Vauch. Why should I have a chance to stay here with my mother?\" \"Why should you have a chance to do so?\" \"Why, when you come to us in our present circumstances, cannot you say that there is a great difference?\" \"My dear child,\" repeated the little boy. \"I think we are in a very delicate moment.\" Monsieur Vauch and the little boy were asleep; and the boy was about to say the thing that he had told his mother. \"The young man asked me what was the matter,\" he said; \"I told him—I tell you everything. Why? He didn't like your answer, and therefore we left the village on board the ship. Our boat sank, Monsieur Vauch had left the village and went to the harbor. The other captain and his men had been sailing with him, and my old captain gave orders for him and for all the other officers to go with him. When Monsieur Vauch's boat sank in the harbor, we landed on board; now Monsieur Vauch had no idea of that. He sat down with his hand on his breast. \"Oh,\" he said slowly, \"my darling child, Monsieur Vauch, I wish you would say there, Monsieur Vauch, is a little strange. That is what makes me so happy.\" \"Oh, you must talk to Monsieur Vauch about it,\" repeated the old captain; and what followed was a whole lot of talking of my feelings for my daughter; but it was not an easy affair. I was very late to-day; but in those days I could speak with a very high voice, and the boy was quite in a hurry to speak. When we were in a great hurry there had been two days at sea\n",
            "\n",
            "[61 | 7460.85] loss=3.29 avg=3.21\n",
            "[62 | 7578.97] loss=3.00 avg=3.21\n",
            "[63 | 7696.17] loss=3.22 avg=3.21\n",
            "[64 | 7814.12] loss=3.12 avg=3.21\n",
            "[65 | 7930.58] loss=3.05 avg=3.20\n",
            "[66 | 8047.84] loss=3.21 avg=3.20\n",
            "[67 | 8164.59] loss=3.15 avg=3.20\n",
            "[68 | 8282.41] loss=3.16 avg=3.20\n",
            "[69 | 8398.82] loss=3.14 avg=3.20\n",
            "[70 | 8515.67] loss=3.58 avg=3.21\n",
            "[71 | 8633.23] loss=3.14 avg=3.21\n",
            "[72 | 8750.76] loss=3.57 avg=3.21\n",
            "[73 | 8868.05] loss=2.98 avg=3.21\n",
            "[74 | 8985.10] loss=3.28 avg=3.21\n",
            "[75 | 9101.98] loss=3.08 avg=3.21\n",
            "[76 | 9219.25] loss=3.46 avg=3.21\n",
            "[77 | 9336.65] loss=3.06 avg=3.21\n",
            "[78 | 9454.13] loss=2.90 avg=3.20\n",
            "[79 | 9570.71] loss=3.07 avg=3.20\n",
            "[80 | 9687.20] loss=3.27 avg=3.20\n",
            "======== SAMPLE 1 ========\n",
            " you be honest? I will tell you I have never heard of an incident, but will tell you about one. My good Lord, I am told that all the men of the world, who are still in their great, old age, were now married, and there are about four million men in America, now married. And the first thing in the first place that I say, is, that the Lord knew what he ought to know, for I am told he married all the men of America, except two, and he was only a little late; but that my lord did not marry a little earlier. I know not what else I will tell you. But I will tell you now, if anybody will. Here I will be bound up, and I mean to keep alive this old story, that I knew of an incident. It is very probable that my lordship may have known of it when he married. I do think it true, when I was married, that I had a little bit of land to spend on the land, which I left, and it may now make some sort of profit. You have heard of a large, but very distant man, a Frenchman, who married my husband, and a few other gentlemen of the family who had the land before he was married, and, after leaving the family, that the man took to the land, and that it was very small, and he soon left it behind. Now, I must say, that I think he married very little, the little number was not very great, and perhaps two years later, he may have left the land behind, to take possession of some more land. I will never be able to tell, if I were to marry one of these gentlemen, unless I shall get my little land, and have him take me to his land. I must say, that I could not wait to get some more land, until I found out the other ladies had left the family behind. When I came home we talked more, and I found one who did know about a little girl. I asked her, on having told the lady of our family, for the time, what I should do. She said nothing, and I told her, when I returned, that I was married to the lady of our family. Now I am married too to have another little girl and I never have any other wife till that time; but I do not doubt that I may have to wait another year, because I know the ladies already. And now, when I am come here I will soon see them again at last, for I have never seen a more great looking gentleman of their family than my good Lord, who was such a good husband and master of his young, poor wife. I should quite like to have another little girl, if he could have one, but then I do not know of one, which I would rather wait till he had been married.\" \"I shall always love a man as much as I do. Then, I shall have a young lady, and I will get her. But I will never take her to a man of the world unless I have her be with another gentleman and have him take me to the estate.\" \"And what you will marry me for, and how you will do it, for I will know the others?\" \"My dear, my goodness, what do you want. I shall have two daughters who like one good husband, and they will all like her.\" \"That does not seem like the best way\" said my good Lord, as I entered his company. \"But you will marry one of the men of the world, and I shall take him to my good lord, and he shall be a rich one for life with so many children, that, if he had no parents he should be a poor one. So I will, and I shall have two young ladies, and let them have children, till they have all learned how to marry well. But at least they will have plenty and that will make their child well, for their first parents are the real husbands of their children, and that I will have some poor little people so that I have a good quality of a family.\" \"You must have good young ladies, my lord,\" said the rich lady. \"You will love many, I must have them,\" said the rich lady. \"But no one will love me in love more than you do,\" answered the rich lady. \"And you will love a very very rich gentleman,\" said the rich lady. \"And you will go as far as you can find before marrying one of the others, and to the estate. No one will marry the poor gentleman, and I shall think it better to have him marry me, than it is better to have him marry me. There are not many men in the world, so you and I can marry together, except one, and he is no one. I shall go so far as far as I can to have two poor young ladies, and I will be happy. But I can do nothing then,\n",
            "\n",
            "[81 | 9904.88] loss=3.06 avg=3.20\n",
            "[82 | 10021.87] loss=3.15 avg=3.20\n",
            "[83 | 10138.33] loss=3.11 avg=3.20\n",
            "[84 | 10255.35] loss=2.97 avg=3.19\n",
            "[85 | 10372.07] loss=2.93 avg=3.19\n",
            "[86 | 10488.93] loss=2.79 avg=3.18\n",
            "[87 | 10606.48] loss=3.27 avg=3.18\n",
            "[88 | 10723.73] loss=3.14 avg=3.18\n",
            "[89 | 10840.27] loss=3.02 avg=3.18\n",
            "[90 | 10957.62] loss=3.31 avg=3.18\n",
            "[91 | 11075.21] loss=3.40 avg=3.19\n",
            "[92 | 11192.72] loss=3.00 avg=3.18\n",
            "[93 | 11310.18] loss=2.99 avg=3.18\n",
            "[94 | 11428.22] loss=3.26 avg=3.18\n",
            "[95 | 11545.57] loss=2.90 avg=3.18\n",
            "[96 | 11662.63] loss=3.08 avg=3.18\n",
            "[97 | 11779.09] loss=3.40 avg=3.18\n",
            "[98 | 11896.26] loss=2.95 avg=3.18\n",
            "[99 | 12013.25] loss=3.16 avg=3.17\n",
            "[100 | 12130.16] loss=3.08 avg=3.17\n",
            "Saving checkpoint/fine_tuning_run_1/model-100\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to continue training a model after already trained it, you should\n",
        "# use restore = \"latest\" and reuse_ = tf.compat.v1.AUTO_REUSE\n",
        "batch_text = open(\"batch_text.txt\", 'w')\n",
        "counter = 1\n",
        "with open(\"custom_dataset.txt\", 'r') as f:\n",
        "  for line in f:\n",
        "    if batch_text.closed:\n",
        "      batch_text = open(\"batch_text.txt\", 'w')\n",
        "    batch_text.write(line)\n",
        "    if counter == 200: \n",
        "      ops.reset_default_graph()\n",
        "      sess = gpt2.start_tf_sess()\n",
        "      gpt2.finetune(sess,\n",
        "                    dataset=\"batch_text.txt\",\n",
        "                    model_name=model_size,\n",
        "                    steps=100,\n",
        "                    restore_from=\"latest\",\n",
        "                    run_name = run_name,\n",
        "                    print_every=1,\n",
        "                    sample_every=20,\n",
        "                    save_every=50,\n",
        "                    reuse=tf.compat.v1.AUTO_REUSE)\n",
        "      batch_text.close()\n",
        "    counter += 1\n"
      ],
      "metadata": {
        "id": "IlawjEn2G-AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvL8l2rCcp-V"
      },
      "source": [
        "End of training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load from drive"
      ],
      "metadata": {
        "id": "VcPgHTfzq3CW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWGNVgMekNQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e625a3-3191-469b-f0c7-3f52479f5994"
      },
      "source": [
        "#This will be the model name we want to load\n",
        "run_name = 'fine_tuning_run_1'\n",
        "print(run_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fine_tuning_run_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt2 should be downloaded\n",
        "model_size = '124M'\n",
        "gpt2.download_gpt2(model_name=model_size)"
      ],
      "metadata": {
        "id": "oTsyEUtipPjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa05b2b-a935-4d7a-e3b0-53c237a7bc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 483Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.90Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 606Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:11, 44.5Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 249Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 8.61Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 7.32Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3bbab4-7739-440f-97ab-032242661d5f"
      },
      "source": [
        "# Copy the model from G-Drive if it wasn't trained in this Colab session.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name=run_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3409c546-6886-4bd6-e89f-1b4ae9e689d9"
      },
      "source": [
        "# Load the model.\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=run_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/fine_tuning_run_1/model-1900\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_1/model-1900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continue training from drive"
      ],
      "metadata": {
        "id": "uXvN3yk9nbYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run this only if you want to continue training the checkpoint you loaded two cells above\n",
        "file_name = \"custom_dataset.txt\"\n",
        "run_name = 'fine_tuning_run_1'\n",
        "gpt2.mount_gdrive()\n",
        "gpt2.copy_file_from_gdrive(file_name)\n",
        "batch_text = open(\"batch_text.txt\", 'w')\n",
        "counter = 1\n",
        "with open(\"custom_dataset.txt\", 'r') as f:\n",
        "  for line in f:\n",
        "    if batch_text.closed:\n",
        "      batch_text = open(\"batch_text.txt\", 'w')\n",
        "    batch_text.write(line)\n",
        "\n",
        "    # we only trained the 200 top stories due to hardware limitations\n",
        "    if counter == 200: \n",
        "      ops.reset_default_graph()\n",
        "      sess = gpt2.start_tf_sess()\n",
        "      gpt2.finetune(sess,\n",
        "                    dataset=\"batch_text.txt\",\n",
        "                    model_name=model_size,\n",
        "                    steps=100,\n",
        "                    restore_from=\"latest\",\n",
        "                    run_name = run_name,\n",
        "                    print_every=1,\n",
        "                    sample_every=20,\n",
        "                    save_every=50,\n",
        "                    reuse=tf.compat.v1.AUTO_REUSE)\n",
        "      batch_text.close()\n",
        "    counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhgCjISJnYeO",
        "outputId": "d28b1cca-02e3-4fce-b23b-35f4085672a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint checkpoint/fine_tuning_run_1/model-1900\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_1/model-1900\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [01:52<00:00, 112.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 26319678 tokens\n",
            "Training...\n",
            "Saving checkpoint/fine_tuning_run_1/model-1900\n",
            "======== SAMPLE 1 ========\n",
            " my position, as he was one of the most trusted men in our society,—\"I must have you to confess that it would, if I could come to you. You may trust me to-night, and you may go to bed, if your soul wants it, without being at home,—I promise you it will not be so without your consent. I should be glad to take refuge without danger from all the world,—there was always a safe place, and you would not have an enemy. But I will not go to sleep, for you know very well that you know the world, for that you will be safe from all danger. That is to tell you the whole truth,—I should be happy to go, if you would give me the strength I desire. I have the heart to do it so,—but I would not do it so much without your consent....\" Then there was a sudden, rapid, and violent stir in the room. Mr. and Mrs. Rouncewell came out of the shadows, and they rushed out of the room together. It was only Mr. Rouncewell who saw them. “Mr. and Mrs. Rouncewell,” he called to them, “you are going to be with me to-night.” They rushed into the room, and they ran into the great hall. Mr. Rouncewell was at the door, but his hair was white and his clothes hung down. They all turned to look at him. Then they all ran into the hall, and they turned again, too,—it was no difficulty to hide themselves. The hall was a great, gloomy one, and every single room had a smell of musk,—and, as their spirits seemed to be growing, they had been made to have a cold—because in this hall of the past the air was sweet, and every thing of a sweet smell of wine was being used to wash their faces. It had become a very dark place for a crowd. The windows seemed shut, and shut, and shut again—if in that hall there were nothing to do but stand and gaze at a window they must take down, and have a cold—for they were so miserable to look at,—that they might have to be dressed, and even have a gown, and take a gown,—because of what they had so many things to do.... At last as they closed their windows the hall was quite dark, and they ran out the hall together; but Mr. Rouncewell, who was asleep, and was not yet out of the chamber, was asleep. We are all very much astonished and surprised. We have only just seen what a thing might be like in a world of such dimness,—it is very well; for a little time, when we are very near the edge of the darkness, there is still a very small street near the place, which by the moonlight is pretty well visible; and indeed it is as dim as ever! It is, indeed,—a street of all dim things,—the narrowest of those, with its sides of the trees, and in the same height. It is very dark in the middle,—it is quite as thin and very thin as it gets round; for it is very dark, when we come in to the place; and as I am in the midst of it, it is very large,—it is a good one,—it has a very deep, deep, deep, deep, deep, and it is very large when he is asleep. And there is a very large window,—very large! That is to be understood,—it is quite large. “Mr. Rouncewell,” began the most wonderful man in the room,—“it is very large,—it has a very deep, deep, deep, and it is very large when he is asleep, and when he is asleep, at any time.” And the greatest, and most beautiful thing,—and with all the grace of a miracle,—he ran out of the room, and ran back to the bed.—This will seem to you very strange—the greatest, true, and all the beauty of a woman,—the happiness which a woman of the best birth can bring.—Well be it understood,—I have always been pretty much the greatest—and, in truth, I have seen in a very fine, true, true, true! And I have seen in it many, many, many more wonderful women—not, perhaps, but in one thing I am sure,—what there is of an angel, and what nothing of a woman; there is in this house every kind of woman—except that the one, which I know the most perfectly, is the greatest, and for the highest part the most beautiful in everything; and yet there is nothing so beautiful as a woman-woman, or at any other moment! And to-day, however much I love her most deeply, I am too much of this to take her as an actual lover,—never, however, shall\n",
            "\n",
            "[1901 | 33.29] loss=3.40 avg=3.40\n",
            "[1902 | 37.71] loss=3.12 avg=3.26\n",
            "[1903 | 42.13] loss=3.01 avg=3.17\n",
            "[1904 | 46.56] loss=2.80 avg=3.08\n",
            "[1905 | 50.99] loss=3.00 avg=3.06\n",
            "[1906 | 55.43] loss=2.94 avg=3.04\n",
            "[1907 | 59.86] loss=2.38 avg=2.94\n",
            "[1908 | 64.31] loss=3.41 avg=3.00\n",
            "[1909 | 68.74] loss=3.04 avg=3.01\n",
            "[1910 | 73.17] loss=3.05 avg=3.01\n",
            "[1911 | 77.60] loss=3.14 avg=3.03\n",
            "[1912 | 82.04] loss=2.91 avg=3.01\n",
            "[1913 | 86.45] loss=2.75 avg=2.99\n",
            "[1914 | 90.86] loss=3.06 avg=3.00\n",
            "[1915 | 95.30] loss=3.28 avg=3.02\n",
            "[1916 | 99.73] loss=3.27 avg=3.04\n",
            "[1917 | 104.15] loss=2.75 avg=3.02\n",
            "[1918 | 108.57] loss=2.93 avg=3.01\n",
            "[1919 | 113.00] loss=3.23 avg=3.02\n",
            "[1920 | 117.43] loss=3.14 avg=3.03\n",
            "======== SAMPLE 1 ========\n",
            " reached the window, and heard the cry of a child as it rushed from the windows. One by one he drew his father's hat along at the same time as Mr. Harkness would have his eyes fixed upon it. With both of them it was all that escaped it, and so Mr. Harkness was forced to go away. His name came back to him as the name of his uncle, whom he had named for his grandfather. He met Mr. Harkness at the gate, and told him what he knew of his uncle. Mr. Harkness, too, came back to assist Harkness in his search. He saw on the window-scratching of the roof a little boy, as if he had been trying to find some way out of it. Mr. Harkness asked him what he knew of this boy. He told him what he knew about his grandfather, and said that the boy went down the street to his own home. When he came back he found that this boy had lost his mother. The boy was in good humour, but with a slight sense of his own weakness. He told him that if he would give his consent he would go with him. They made up their minds immediately, and he went to meet his grandfather. He walked into the room, holding the boy by the hand, and then he turned down and began to talk about the boy who had been killed. Then Mr. Harkness looked over the boy. The boy looked at him as if he had a dream. He was small, and he had grown very stout. He was dark, and was not at all like a human being. Perhaps it will be a great help to him to be brought up to life as he may and to make his grandmother proud again, and to know that the world can be proud of him, and to be able to make him proud too. He was not proud, though, for the boy had lost his mother. He was not afraid, and was afraid of the grandfather. He had a brother and a sister, and he was afraid of the grandfather. He could not help his brother in his sorrow. Then he told his mother what had happened, to make her happy, and his family knew him and supported him. He had always been an ordinary boy, a little boy, but suddenly he began to be an ordinary boy again, and when he was three or four there lay a horrible and sickened hand between him and his mother. She could have left him and had given him up to another family, but she had never done this. He was an orphan, and she had told him everything about her grandfather. He was ashamed that she had not come to his aunt's and told her that he was useless and wanted to help her. She went away in despair. Mr. Harkness was afraid that the boy would go with them, and could not help thinking that he was hopeless of getting into a better manner, and that he would have to be an absolute coward. He said that he would turn out of doors, and that he would not leave him until he had got home. He was so sorry for him that he was glad of all he had suffered for the sake of the boy. At last, he told his mother that he would be sure to stay with the boys. He told her that he was glad to keep them together, and that he would be glad enough to let them be together together, and he would do as he liked. He told her that it was to be a great honour to him that they should do so together, and that she would be happy to take care of them all together. They were to spend the whole night together, and the night would be spent together in their old cottage, and every day it would be his turn to look after his old grandmother. After dinner at a great dinner, Mr. Harkness and his mother looked in and found a little boy lying on a chair by himself. He had a strong arm, very small and a little grey as a hedge. He was white with a greenish scar on the back as of a horse. The boy sat on the arm, on the chair, and the doctor said to him: âI wonder what my doctor thinks of it.â After a long sitting, the baby was put in a little bottle into a little bottle. He had an odd looking face and he had a strong sense of humour, though he was only eight and ten years of age. The doctor said of the baby: âThat they were quite sure to get a mother that their doctor could do to them.â The baby was a little red boy, about nine months old, with grey hair; a big moustache, and a good nose. The doctor was looking at him and saying: In the winter he is not to be named. âHere is a medicine for an operation like this.\n",
            "\n",
            "[1921 | 138.23] loss=3.09 avg=3.03\n",
            "[1922 | 142.68] loss=2.91 avg=3.03\n",
            "[1923 | 147.10] loss=3.05 avg=3.03\n",
            "[1924 | 151.54] loss=3.48 avg=3.05\n",
            "[1925 | 155.95] loss=3.25 avg=3.06\n",
            "[1926 | 160.38] loss=2.92 avg=3.05\n",
            "[1927 | 164.82] loss=3.28 avg=3.06\n",
            "[1928 | 169.25] loss=3.00 avg=3.06\n",
            "[1929 | 173.68] loss=3.01 avg=3.06\n",
            "[1930 | 178.10] loss=3.02 avg=3.06\n",
            "[1931 | 182.52] loss=3.12 avg=3.06\n",
            "[1932 | 186.94] loss=3.12 avg=3.06\n",
            "[1933 | 191.37] loss=3.14 avg=3.06\n",
            "[1934 | 195.79] loss=2.75 avg=3.05\n",
            "[1935 | 200.23] loss=2.75 avg=3.04\n",
            "[1936 | 204.66] loss=2.91 avg=3.04\n",
            "[1937 | 209.08] loss=3.03 avg=3.04\n",
            "[1938 | 213.51] loss=2.72 avg=3.03\n",
            "[1939 | 217.91] loss=2.96 avg=3.03\n",
            "[1940 | 222.34] loss=3.06 avg=3.03\n",
            "======== SAMPLE 1 ========\n",
            " useless and unfulfilled hopes, and it was with their last, or rather, they died. In consequence of their death, they lived in a state of constant suffering and misery, and the last, or rather, they lived in a state of perpetual agony and misery.â âWhat did the doctor say?â Mr. Darcy inquired, as if his companion had been listening. âHe said nothing.â âWell,â said Mr. Darcy âI am satisfied with the way the doctor gave us that his heart was beating just as rapidly as his head. We will tell what I think, now, and I hope you will be glad,â said George. âI should be grateful for all his kindness,â said George to Mr. Darcy. âI never should have known it, I think,â said Mr. Darcy. âI know that they lived at that house, and every one at that house was always good enough to the children.â âIn the villageâ (looking at the table with his red eyes) âwe had two boys, Mr. George and Mr. Thomas.â âOh, _they_ live in the village, then,â said Mr. Darcy, âand there are all sorts of things which one man must have for his own children.â âIt was just an unkindness of the place,â said George, âand he is a pretty big boy too. I heard him say, in a very bad tone at the hospital, that I may have some money for my own children.â âMr. Thomas is a little old of seven, he said,â continued Mr. Darcy, with the greatest eagerness; âand the way you say he was never born. I suppose that they were all born with this one little stick behind their ears.â âHe was,â said George, âand they lived just here and there about ten-tenths of a mile from the river.â âThen I was told then that a very, very nice, little child could live in his house without any special care or assistance.â âOh,â said Mr. Darcy, âit would save the trouble. Here we will talk about it.â âIt was an unkindness of the place,â said George; âand I heard him say of the girl whom he had brought me home from Paris: that she used to go after them, and had a sweet little head to look at. And that her head was white with her head-cloth! What sort of her she was! I never heardânot a little.â âNo,â said George, âbut at least there was no fault in her, though she had been so much neglected to the last.â George had been thinking of all this, and he had determined that his opinion of them should be respected; and he hoped that he would be always so disposed to be a better judge, and more sympathetic to her, that no harm should be carried to him. But at the same time, without the knowledge of the people. George had a little idea that he had made a mistake in giving some information that they were all born with a stick behind their ears. They were so much more familiar with one anotherâs names that a common knowledge of him was unnecessary. They were always talking about them. They talked of them as if they had been grown up, and they listened almost as if they had been raised, while they were talking. And George was aware of how strange they all looked and felt; but, in spite of this general interest, they always talked of him as if he had been made up of the very old earth. And it seemed as if people in that village could be as ignorant of him as they were of his family. A little boy sat beside his mother at the table and began to talk, and George was quite\n",
            "\n",
            "[1941 | 243.25] loss=3.22 avg=3.03\n",
            "[1942 | 247.67] loss=2.64 avg=3.02\n",
            "[1943 | 252.09] loss=2.49 avg=3.01\n",
            "[1944 | 256.52] loss=2.93 avg=3.00\n",
            "[1945 | 260.94] loss=3.39 avg=3.01\n",
            "[1946 | 265.36] loss=2.86 avg=3.01\n",
            "[1947 | 269.79] loss=2.93 avg=3.01\n",
            "[1948 | 274.20] loss=3.18 avg=3.01\n",
            "[1949 | 278.63] loss=3.30 avg=3.02\n",
            "[1950 | 283.07] loss=2.76 avg=3.01\n",
            "Saving checkpoint/fine_tuning_run_1/model-1950\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "[1951 | 290.04] loss=3.26 avg=3.02\n",
            "[1952 | 294.48] loss=2.90 avg=3.02\n",
            "[1953 | 298.92] loss=3.11 avg=3.02\n",
            "[1954 | 303.35] loss=2.92 avg=3.02\n",
            "[1955 | 307.79] loss=2.31 avg=3.00\n",
            "[1956 | 312.21] loss=3.18 avg=3.00\n",
            "[1957 | 316.63] loss=3.18 avg=3.01\n",
            "[1958 | 321.05] loss=3.02 avg=3.01\n",
            "[1959 | 325.48] loss=2.85 avg=3.00\n",
            "[1960 | 329.91] loss=3.32 avg=3.01\n",
            "======== SAMPLE 1 ========\n",
            " in his eyes, and then came out of it, too. \"Your brother,\" he said, \"has something to say, sir. I will ask you for your assistance in this matter.\" \"I am so glad,\" he answered, \"that you would answer for our offer, but I must speak for myself.\" Then he left the room. The others rose before him and left, but the count had gone away. The maids who were dressed like birds began to laugh. \"Here you will give me back my brother!\" cried I, as he came out from the room. \"He is a beautiful man, to speak truth to! I have heard him talk of my father's death. It is impossible I can do what he wants. I will ask you to tell me, but first I must confess that I have done my work for him, and you will understand how little I am able to do for you, and how dear I are to you.\" \"There is no more for you, madame. Look at that splendid figure which I have laid before you. I must confess I am an artist, and if I have had nothing to say to you, as I have said many times before--or perhaps I have not, you know--I would beg you to tell me.\" \"What art and what art does art, or the devil, or some such art, have at my command? You know that I cannot say, but that is a fact. You can have no objection.\" \"But you have never been to see him. You cannot have it!\" \"Never have I, because I have only to tell your father the truth. I will go to you and say nothing to you, but you could only do it for one of your people.\" \"You can think of nothing to do for me. In a world of love, if that is how it is your pleasure to love, how can you think of love? If I knew how to love all your people, my life would be a complete failure! I have only three friends, all of whom are servants, and you are your mother. You need only tell me what will it cost you to give up your friendship. Tell me.\" \"You are no longer a good wife for you. You can have no friends, and I shall be your wife, but I shall be no good wife for anything, so tell me that you are a good woman for it. In a world of love, to marry is a disgrace, and I will do what to you will. Tell me what is the trouble? Tell me the reason.\" \"Do you suppose that will cost me much? How can you tell me the trouble?\" \"Yes, but what I ask you is the same question I ask the count. You have had a poor marriage which will cost you everything!\" \"You did very ill yourself, sir, and I told you to tell me why: you knew by what I have told you that all things are possible when they are meant to be possible; you were not allowed to be silent and to take my word for it; you did not respect my word, you were ashamed of your father, and you should have told me how much more you loved him, but I have not yet told you.\" \"What am I to do? You have come in the heat, you are not permitted, but you must let me have my share in the trouble; I can give you my share as well as myself, and I have the authority to do so. But first I must tell you the reason for your leaving the house and you cannot speak of it any further. Then I will try the matter as amiable. In a world of love, to marry is a disgrace, and I will try to get a good wife for you, for your people would die for her, and at least she is not yours. Do you think that will cost you much? Of course I will try it now, and it will cost one of your people, and you will come back home and do me for you. Do not tell me that you may go. I cannot go on living till you tell me. I shall never forget you once for life, and I will do you for an excellent wife! My mother is a little girl, but is not a girl that has given you trouble but a simple, fair, and affectionate woman, and I can give her everything I can, for you would be in the danger of giving up your friends in the worst way. Tell me what the trouble is. You have been taken with you to a town where I have to live and I was to live a very painful time. This was the first time I had to take care of my mother, and she did so most carelessly, that my father did not come to see me again; but she loved me like a sister, she did not like to see me, for she loved myself like a good mother. When it was this that caused me to leave the house with my friends, she was frightened,\n",
            "\n",
            "[1961 | 350.75] loss=3.42 avg=3.02\n",
            "[1962 | 355.18] loss=3.31 avg=3.03\n",
            "[1963 | 359.61] loss=3.26 avg=3.03\n",
            "[1964 | 364.04] loss=2.78 avg=3.03\n",
            "[1965 | 368.45] loss=3.40 avg=3.03\n",
            "[1966 | 372.86] loss=2.91 avg=3.03\n",
            "[1967 | 377.28] loss=2.96 avg=3.03\n",
            "[1968 | 381.71] loss=2.78 avg=3.03\n",
            "[1969 | 386.13] loss=3.18 avg=3.03\n",
            "[1970 | 390.56] loss=3.34 avg=3.03\n",
            "[1971 | 394.98] loss=2.67 avg=3.03\n",
            "[1972 | 399.41] loss=2.70 avg=3.02\n",
            "[1973 | 403.84] loss=2.99 avg=3.02\n",
            "[1974 | 408.25] loss=3.09 avg=3.02\n",
            "[1975 | 412.68] loss=3.07 avg=3.02\n",
            "[1976 | 417.09] loss=3.32 avg=3.03\n",
            "[1977 | 421.51] loss=2.76 avg=3.02\n",
            "[1978 | 425.94] loss=3.18 avg=3.03\n",
            "[1979 | 430.38] loss=2.67 avg=3.02\n",
            "[1980 | 434.80] loss=3.04 avg=3.02\n",
            "======== SAMPLE 1 ========\n",
            "� âWhat do you mean?â âA little more!â cried Miss Peleg, a little alarmed, âI tell you it is very strange how the world looks at me now! And, what an extraordinary effect it gets on you! There is something about your appearance, even with you that I never noticed at first because I was not sure I could see it.â âOh! you seem to have suffered from strange illness; I see that you don't care for the disease as I do; I see that you've got into the habit of thinking of the world as a sort of blind, and you've a very large idea of yourself as an important figure, a person of importance to other men.â âYou're the person who ought to be in the world,â rejoined Holmes, âyou look so like a real man.â âWell, and the reason for your change of character is, that the change was not quite so as you supposed and I should not have thought it possible for you to be.â âExactly!â said Holmes; âI was very much astonished when your name was mentioned and the conversation went on in the world. But, after it you didn't know anything. But, after you were in London with you, and you told me nothing of the world, I can't believe I knew it!â âIt came to my mind,â said Holmes, âthat you were a very well-known man there.â âI don't know.â âWell, that was not the case. I never saw you again for many years. I've lived with you in your hotel. What was it then about?â âIt was a bad one.â âI suppose it is. They may do you justice to what it is now. However, I'm not so sure it is impossible that you must have been born in England at that time, in that street, or at some other place.â âThat may have been your idea; but what a queer way you must have lived, that you might have gone over your head to London in this world and met with many strange things; you might have seen a great deal, and could have imagined yourself at an unknown place and with a great deal to lose for ever of which there is no truth. But what is the truth?â âI thought.â âThen, I must say, that you were a really pretty pretty person,â said Holmes, âand that your thoughts sometimes went towards things which were awful, and which, however, you thought you were going to kill. You thought yourself a great risk and would have taken it out.â âThat was my point on that point. Why should I give up the man?â âHe was quite a quiet man,â said Holmes. âAt least, it was not in his nature to be agitated. He never looked in the street, though he had an awful fever.â âWell!â cried Miss Peleg. âThe idea, you see, struck me particularly. Wasn't Holmes a man of much importance to you?â âI know I am not, I know.â âAnd was it for me that was the case?â âNo; for I was not sure he was a very remarkable man.â âWhat does he look like?â âPerhaps he doesn't make use of his new name in these days. Perhaps he will be able to tell me what he is in a minute.â âWell, no! I think he has a few words to say, but he won't tell; he can never be heard.â âOh, that is very surprising!â\n",
            "\n",
            "[1981 | 455.60] loss=3.18 avg=3.02\n",
            "[1982 | 460.02] loss=2.94 avg=3.02\n",
            "[1983 | 464.47] loss=3.31 avg=3.03\n",
            "[1984 | 468.89] loss=3.30 avg=3.03\n",
            "[1985 | 473.33] loss=3.24 avg=3.04\n",
            "[1986 | 477.76] loss=3.00 avg=3.03\n",
            "[1987 | 482.17] loss=2.74 avg=3.03\n",
            "[1988 | 486.60] loss=3.32 avg=3.03\n",
            "[1989 | 491.03] loss=2.96 avg=3.03\n",
            "[1990 | 495.44] loss=3.30 avg=3.04\n",
            "[1991 | 499.86] loss=3.50 avg=3.05\n",
            "[1992 | 504.29] loss=3.03 avg=3.04\n",
            "[1993 | 508.72] loss=3.20 avg=3.05\n",
            "[1994 | 513.14] loss=3.18 avg=3.05\n",
            "[1995 | 517.57] loss=3.61 avg=3.06\n",
            "[1996 | 521.99] loss=3.12 avg=3.06\n",
            "[1997 | 526.42] loss=2.82 avg=3.06\n",
            "[1998 | 530.84] loss=2.73 avg=3.05\n",
            "[1999 | 535.27] loss=3.12 avg=3.05\n",
            "[2000 | 539.70] loss=3.36 avg=3.06\n",
            "Saving checkpoint/fine_tuning_run_1/model-2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iofztc2f-58U"
      },
      "source": [
        "# Unconditional generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b97a61b-e393-42a0-9a82-b88b87517366"
      },
      "source": [
        "gpt2.generate(sess, run_name=run_name, temperature=.9, length=200, prefix=None, top_k=20, top_p = 0.95, nsamples=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "had the differentials of that theory that, while being finally in favour of freedom of speech, it would be unjust to refuse the offer to which he was, indeed, to give credit. The rights of freedom were only justly understood by those who agreed to it and whose own forms of protection could be most easily found by those who had not. At last, as to liberty, it must be confessed that the denial was very necessary. Mr. Morland had asked him himself, and his friends, to make a exact list of all the acts which had been proposed to him; and to no purpose had he now any other of those principles against freedom. To this he was obliged to add two additional provisions, that he could now forbid the mention of the name of an individual, and he must have a right in connection with this that he could so firmly denominate and describe his own case to his own and to the justice of the district court. This second check was concluded by a declaration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Es5HiU_GGm"
      },
      "source": [
        "# Conditional generation (give the model an input prompt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82hy6qlX_FtR"
      },
      "source": [
        "input_prompt = \"Once upon a time\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WY9OUZmMqEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e089c166-b146-4f8e-f6fd-5cafdad4ed01"
      },
      "source": [
        "gpt2.generate(sess, run_name=run_name, temperature=.9, length=200, prefix=input_prompt, top_k=20, top_p = 0.95, nsamples=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time does not come to speak to her pain or anger, or to give her the knowledge that she loves this man, that she must not have understood him, or that she will not at all see him at once. O, my dear My God, do not at once perchance, in this world a notice come to my eyes, or to my heart, that I am befogged, or that my reward will be completely wiped off my sleeve. But this is not all, all that comes to my lips; I say that in this present world I am like the sailor on board a ship of the Japanese government. These people will wear me into their bosoms, and they will take me off to beheaded. They will dress me in unsealed outer garments, and I will be devoured as if I had been a slave. And when I have sat to this they will utter those last words of life and death: “He is the soul of the world, that I have\n",
            "====================\n",
            "Once upon a time, in the light of rising and going therefrom, the lorry comes over hill and road, not dimly lit from the road. There seems to be some difference between the main road and the hill with the hollow in front, and it turns into a narrow corridor, so that there is not any end. As soon as we were on the road, at some distance from the road, the lorry comes to a stop. It is bent, and as we were going up, the driver is on the grass in a row, in a way, with his back turned towards the road. He looks at us with a very hurried face. âAre you approaching the railway?â âI am, I repeat,â answered he. âThe railway?â âYes, sir,â answered the lorry\n",
            "====================\n",
            "Once upon a time, as you say, there was not a fish in the sea to be seen. There was not in the sun. There was not a bird in the sky. There was not a cloud. There was no sun, nor a cloud. Some day at night, I can be bound to you by your word, if you will not tell me so. Have not I ever written a note to you? And if you have a note of mine, you know that I never took your hand. Do you know what I write on the note? It is done at night. If I had a note of it--if I had a note of it--I never took your hand. I do not take your hand. Do you know what I say when I write it down? I do not take your hand. I do not read it. I get all written down. I say it aloud, and it's on the pen, but I don't take it off. You can take the note\n",
            "====================\n",
            "Once upon a time a crisis come upon the family of an adjoining star. It was not so, and she was so much filled with rage, not so, that she did not know what it was; but she had no idea at all what it was, for she knew not one word of it, and had no reason for the rage that came upon her. She gave the then arriving starilance to her, and, on the next day, sent in an army of bees to assist her in recovering her strength, as she supposed she might have been so suffered. There was a little moment in the midst of her rage which lasted in great despair, when she saw a large white bird fly into the air, and make a great noise, and strike upon the earth. So she scrambled forth of the jungle, and, splashing with a certain smell of it, began to cry out, but presently she saw, by a heavy noise of the air, a large bird, flying down, and, getting the\n",
            "====================\n",
            "Once upon a time him first entered the chamber where Mrs. Blifil de Harte was found, and discovered the room in the same garret, and so immediately she entered with the lady. The lady also came to look, and as she saw by Mrs. Blifil's glance that she was anxious to see the lady and the lady-servant, she hastened to comfort the lady and addressed her. âFirst,â said the lady, âyou did well, as you were never to fall ill with the fever, and one should be sure to receive your health from us. But I do not give a comfort to poor Mrs. Blifil. She had a very cunning disguise, and it has cost her one fine day the very usual family trouble.â âShe was the first to see the lady,â said the lady, â\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "Nv_kXhJ7vFhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daMaaUrs9Pg3",
        "outputId": "adf9a11d-e99e-46dc-add4-429153d9c4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate import bleu"
      ],
      "metadata": {
        "id": "lg2Dfk2-9YCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listToString(s): \n",
        "    str1 = \"\" \n",
        "    for ele in s: \n",
        "        str1 += ele  \n",
        "    return str1 "
      ],
      "metadata": {
        "id": "bMYRqHXYw4TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate import bleu\n",
        "\n",
        "# here we calculate the BLUE and Rouge score for the generated text\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "with open(\"test_txt.txt\", 'r') as testset:\n",
        "  counter = 0 \n",
        "  for line in testset:\n",
        "    # we calculated only for the first 5 books and took the avg score since it was a time demanding task\n",
        "    if counter < 5:\n",
        "      print(\"########\")\n",
        "      print(\"BOOK \", counter + 1)\n",
        "      print(\"########\")\n",
        "      text_length = 70\n",
        "      prefix_length = 10\n",
        "      phrase = line\n",
        "      phrase1 = phrase.split()\n",
        "      phrase1 = phrase1[:prefix_length]\n",
        "      result_gpt2 = ((gpt2.generate(sess, run_name=run_name, temperature=.9, length=text_length, prefix=\" \".join(phrase1), top_k=20, top_p= 0.95, nsamples=1, return_as_list= True)))\n",
        "\n",
        "      string1 = \" \".join(phrase.split()[prefix_length:len(listToString(result_gpt2).split())]) # reference text\n",
        "      string2 = \" \".join(listToString(result_gpt2).split()[prefix_length:text_length+prefix_length]) # generated text\n",
        "\n",
        "      # calculate scores\n",
        "      accuracy = bleu([string1.split()], string2.split(), (1,))\n",
        "      scores = scorer.score(string1, string2)\n",
        "\n",
        "      # print the results\n",
        "      print(\"Input /////// \", \" \".join(phrase1), \" ///////\")\n",
        "      print(\"Ground truth: |\", string1)\n",
        "      print(\"Generated:    |\", string2)\n",
        "      print(\"BLUE score: \", accuracy)\n",
        "      print(\"----------\")\n",
        "      print(\"rouge1 score: \", scores['rouge1'])\n",
        "      print(\"----------\")\n",
        "      print(\"rougeL score: \", scores['rougeL'])\n",
        "      print(\"----------\")\n",
        "      print(\"\")\n",
        "    counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjbg8mlYvudV",
        "outputId": "f25dbf6b-d33b-4a0b-b212-57cb3e8c665c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########\n",
            "BOOK  1\n",
            "########\n",
            "Input ///////  clustered round the fire, by lamplight. \"Well! I'm very glad  ///////\n",
            "Ground truth: | to hear it,\" said Scrooge's nephew, \"because I haven't great faith in these young housekeepers. What do you say, Topper?\" Topper had clearly got his eye upon one of Scrooge's niece's sisters, for he answered that a bachelor was a wretched outcast, who had no\n",
            "Generated:    | of that,â said the cadet; \"even at that moment all I ask is that you do what you have to do.\" He readily gave the answer, saying: âI canât bear another moment to mention that, so I wish to give your father a signal for\n",
            "BLUE score:  0.2\n",
            "----------\n",
            "rouge1 score:  Score(precision=0.30434782608695654, recall=0.2857142857142857, fmeasure=0.29473684210526313)\n",
            "----------\n",
            "rougeL score:  Score(precision=0.17391304347826086, recall=0.16326530612244897, fmeasure=0.16842105263157894)\n",
            "----------\n",
            "\n",
            "########\n",
            "BOOK  2\n",
            "########\n",
            "Input ///////  of seeing great houses; after going over so many, she  ///////\n",
            "Ground truth: | really had no pleasure in fine carpets or satin curtains. Mrs. Gardiner abused her stupidity. âIf it were merely a fine house richly furnished,â said she, âI should not care about it myself; but the grounds are delightful. They have some of the finest woods in the country.â Elizabeth said no moreâbut her mind could not acquiesce. The possibility of meeting Mr.\n",
            "Generated:    | saw up to a thousand people, who were naked and covered with snow; and she was fond of them. Then she gave herself up to love, and lay in the garden, and she drew straw and wood and sweet flowers, and there she put a beautiful rose; after it grew in white and grew straight out of her mouth, and when the\n",
            "BLUE score:  0.16129032258064513\n",
            "----------\n",
            "rouge1 score:  Score(precision=0.1935483870967742, recall=0.19047619047619047, fmeasure=0.192)\n",
            "----------\n",
            "rougeL score:  Score(precision=0.12903225806451613, recall=0.12698412698412698, fmeasure=0.128)\n",
            "----------\n",
            "\n",
            "########\n",
            "BOOK  3\n",
            "########\n",
            "Input ///////  any very pressing need for repairs at that end wall.â  ///////\n",
            "Ground truth: | âThere were none. I believe that it was an excuse to move me from my room.â âAh! that is suggestive. Now, on the other side of this narrow wing runs the corridor\n",
            "Generated:    | âAnd so what?â âSo that with the money they had spent on the attempts at Uptonâor on the junkyardâthey might give me a most handsome deal of money without neglecting the suit.â�\n",
            "BLUE score:  0.1875\n",
            "----------\n",
            "rouge1 score:  Score(precision=0.17647058823529413, recall=0.1875, fmeasure=0.1818181818181818)\n",
            "----------\n",
            "rougeL score:  Score(precision=0.14705882352941177, recall=0.15625, fmeasure=0.15151515151515152)\n",
            "----------\n",
            "\n",
            "########\n",
            "BOOK  4\n",
            "########\n",
            "Input ///////  at all,â said the King: âhowever, it may kiss my  ///////\n",
            "Ground truth: | hand if it likes.â âIâd rather not,â the Cat remarked. âDonât be impertinent,â said the King, âand donât look at me like that!â He got behind Alice as he spoke. âA cat may look at a king,â said Alice. âIâve read that in some book, but I donât remember where.â âWell, it must be removed,â\n",
            "Generated:    | soul, but that is not the end of this. It is a very long and extremely painful affair. The servants are lying all over, trying to draw a line or a line at a writing-table or something; and the Lady is much better and more comfortable now, than she was when she was younger.â â\n",
            "BLUE score:  0.10909090909090911\n",
            "----------\n",
            "rouge1 score:  Score(precision=0.18181818181818182, recall=0.16666666666666666, fmeasure=0.17391304347826086)\n",
            "----------\n",
            "rougeL score:  Score(precision=0.10909090909090909, recall=0.1, fmeasure=0.10434782608695652)\n",
            "----------\n",
            "\n",
            "########\n",
            "BOOK  5\n",
            "########\n",
            "Input ///////  of the water, and retained in that position by the  ///////\n",
            "Ground truth: | enormous cutting tackles, whose hempen combinations, on one side, make quite a wilderness of ropes in that quarter. Thus much being said, attend now, I pray you, to that marvellous andâin this particular instanceâalmost fatal operation whereby the Sperm Whaleâs great Heidelburgh Tun is tapped. CHAPTER 78. Cistern and Buckets. Nimble\n",
            "Generated:    | 'ambrosa, the catch basin, and other loose canoes; which cover the meadows, whose soft, yellow, yellow barkles might be seen beneath, and in the thickets, whose bursting, which accompanied the rising of the sea, or the discharge of water. But there is no west coast in all this. In the place\n",
            "BLUE score:  0.11764705882352941\n",
            "----------\n",
            "rouge1 score:  Score(precision=0.19607843137254902, recall=0.18518518518518517, fmeasure=0.19047619047619044)\n",
            "----------\n",
            "rougeL score:  Score(precision=0.11764705882352941, recall=0.1111111111111111, fmeasure=0.11428571428571428)\n",
            "----------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}